#conexion a spark
sc<-spark_connect(master="local")
sp_oct20<-copy_to(sc,computo,"computo",overwrite = T)
#bolivia
sp_oct20 %>% filter(pais="Bolivia")
#bolivia
sp_oct20 %>% filter(pais=="Bolivia")
dimnames(sp_oct20)
str(computo)
library(dplyr)
#bolivia
sp_oct20 %>% filter(pais=="Bolivia")
sp_oct20$elec
unique(sp_oct20$elec)
table(sp_oct20$elec)
tb(sp_oct20$elec)
tbl_df(sp_oct20$elec)
sp_oct20 %>% group_by("elec") %>% count
sp_oct20 %>% group_by("elec") %>% count()
sp_oct20 %>% group_by(elec) %>% count()
#bolivia elecciones nacionales
bol<-sp_oct20 %>% filter(pais=="Bolivia" & elec=="Presidente y Vicepresidente") %>% compute("bol")
#exterior elecciones nacionales
ext<-sp_oct20 %>% filter(pais!="Bolivia" & elec=="Presidente y Vicepresidente") %>% compute("ext")
bol %>% count()
ext %>% tally()
dimnames(sp_oct20)
#creando nuevas variables
sp_oct20 %>% mutate(tot=sum(cc:pan))
#creando nuevas variables
sp_oct20 %>% sdf_mutate(tot=sum(cc:pan))
#reporte de valores perdidos
sapply(computo, function(x) sum(is.na(x)))
#creando nuevas variables
sp_oct20 %>% mutate(tot=sum(cc:pan))
#creando nuevas variables
sp_oct20 %>% mutate(tot=cc+fpv)
#creando nuevas variables
sp_oct20 %>% mutate(tot=sqrt(cc+fpv))
#creando nuevas variables
sp_oct20 %>% mutate(tot=mas>100)
#creando nuevas variables
sp_oct20 %>% mutate(tot=mas>100) %>% group_by(ddep)
#creando nuevas variables
sp_oct20 %>% mutate(tot=mas>100) %>% group_by(ddep) %>% summarise(mean(tot))
#creando nuevas variables
sp_oct20 %>% group_by(ddep) %>% mutate(tot=mas>100) %>% summarise(mean(tot))
#creando nuevas variables
sp_oct20 %>% group_by(ddep) %>% mutate(tot=mas>100)
#creando nuevas variables
sp_oct20 %>% group_by(ddep) %>% select(mas) %>% mutate(tot=mas>100)
bol %>% group_by(ddep)
bol %>% group_by(ddep) %>% mutate(mas=n/sum(n))
bol %>% group_by(ddep) %>% tally() %>% mutate(mas/sum(n))
bol %>% group_by(ddep) %>% tally() %>% mutate(n/sum(n))
bol %>% mutate(mas100=mas>100)
bol %>% mutate(mas100=mas>100) %>% group_by(ddep)
bol %>% mutate(mas100=mas>100) %>% group_by(ddep) %>% summarise(mean(mas))
bol %>% mutate(mas100=mas>100) %>% group_by(ddep) %>% summarise(mean(mas100))
bol %>% mutate(mas100=mas>100) %>% group_by(ddep) %>% summarise(table(mas100))
bol %>% mutate(mas100=ifelse(mas>100,1,0)) %>% group_by(ddep) %>% summarise(table(mas100))
bol %>% mutate(mas100=ifelse(mas>100,1,0))
bol %>% mutate(mas100=ifelse(mas>100,1,0)) %>% select(mas,mas100)
bol %>% mutate(mas100=ifelse(mas>100,1,0)) %>% group_by(ddep) %>% summarise(mean(mas100))
bol %>% mutate(mas100=ifelse(mas>100,1,0)) %>% group_by(ddep,dpro) %>% summarise(mean(mas100))
#desconectando sesión
spark_disconnect(sc)
2+2
fdjscbncdcbdsv
gfd
vdfgdf
hgthtrhr
4+4
4+4
5+5
5+5
5+5
6+6
5+5
6+6
5+5
6+6
5+5
6+6
shiny::runApp('GitHub/EST-383/code/shiny/ej2')
4+4
shiny::runApp('GitHub/EST-383/code/shiny/ej2')
```{r,eval=FALSE}
library(rtweet)
library(wordcloud2)
bd3<-search_tweets("Coronavirus",n=10000,include_rts  =  F , lang = " es ")
bd3<-search_tweets("Coronavirus",n=10000,include_rts  =  F , lang = " es ")
nube<-function(aux){
docs<-Corpus(VectorSource(aux))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("sp"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
return(df)
}
df<-nube(bd3$text)
library(tm)
df<-nube(bd3$text)
library(wordcloud2)
wordcloud2(data=df,color='random-dark',shape = 'star')
library( syuzhet )
aa <- get_nrc_sentiment ( bd3 $ texto , idioma  =  " español " )
library(syuzhet)
library(rtweet)
#Frase
frase<-"Esa persona es racista, patético y una lacra. otros roban a las personas"
#Generando el léxico en español
lex<-get_sentiment_dictionary("nrc",language = "spanish")
#Ampliando el léxico
lex<-rbind(lex,c("spanish","racista","negative","1"))
lex<-rbind(lex,c("spanish","patético","anger","1"))
lex<-rbind(lex,c("spanish","roban","anger","1"))
lex<-rbind(lex,c("spanish","lacra","anger","1"))
tail(lex)
#Creando la función para obtener la tabla de sentimientos
obtener_sentimientos<-function (char_v, lex, cl = NULL, language = "spanish")
{
if (!is.character(char_v))
stop("Data must be a character vector.")
if (!is.null(cl) && !inherits(cl, "cluster"))
stop("Invalid Cluster")
lex$value = as.double(lex$value)
word_l <- strsplit(tolower(char_v), "[^A-Za-z']+")
if (is.null(cl)) {
nrc_data <- lapply(word_l, get_nrc_values, language = language, lexicon = lex)
}
else {
nrc_data <- parallel::parLapply(cl = cl, word_l, language = language,lexicon = lex,
get_nrc_values)
}
result_df <- as.data.frame(do.call(rbind, nrc_data), stringsAsFactors = F)
my_col_order <- c("anger", "anticipation", "disgust",
"fear", "joy", "sadness", "surprise",
"trust", "negative", "positive")
result_df[, my_col_order]
}
#Resultado Actual
get_nrc_sentiment(frase,language = "spanish")
#Resultado Con la Funcion
obtener_sentimientos(frase, lex, language = "spanish")
rm(list=ls())
load(url("https://github.com/AlvaroLimber/EST-384/raw/master/data/endsa.RData"))
library(dplyr)
bd2<-endsa %>% filter(edad>=20 & edad<=40)
attributes(endsa)
str(endsa)
table(bd2[,15])
str(bd2)
bd2<-bd2[,c(3,6,7,10,11,12,13,14,15,16,23)]
bd2<-na.omit(bd2)
bd2_2<-bd2
#aux<-c(  "depto",  "area" ,  "year" ,  "edad" ,  "sexo" ,  "ae01",
# "ae02"  , "ae03"  , "ae04"  , "ae05"  , "ae06"  , "ae07"  , "ae08",
#"ae09" )
#for(i in aux){
# bd2[[i]]<-bd2[[i]]==1
#}
str(bd2)
table(bd2$ae09)
#table(bd2$vf10)
#base de test y entrenamiento
set.seed(123)
index = sample(1:2, nrow(bd2), replace = TRUE, prob=c(0.7, 0.3))
prop.table(table(index))
trainbd_l<-bd2[index==1,]
testbd_l<-bd2[index==2,]
m1l<-glm(ae09~.,data=trainbd_l,family = binomial(link="logit"))
m2l<-step(m1l)
summary(m2l)
clase_l<-predict(m2l,testbd_l,type="response")>0.5
table(clase_l)
table(testbd_l$ae09,clase_l)
table(testbd_l$ae09,clase_l)
library(caret)
confusionMatrix(table(testbd_l$ae09,clase_l))
frase<-"Esa persona es racista, patético y una lacra. otros roban a las personas"
get_nrc_sentiment(frase,language = "spanish")
#####################################
ww<-get_sentiment_dictionary("nrc",language = "spanish")
get_nrc_sentiment
get_nrc_values
ejemplo<-function (char_v, cl = NULL, language = "english",lexicon=T)
{
if (!is.character(char_v))
stop("Data must be a character vector.")
if (!is.null(cl) && !inherits(cl, "cluster"))
stop("Invalid Cluster")
lexicon <- dplyr::filter_(ww, ~lang == language)
word_l <- strsplit(tolower(char_v), "[^A-Za-z']+")
if (is.null(cl)) {
nrc_data <- lapply(word_l, get_nrc_values, lexicon = lexicon)
}
else {
nrc_data <- parallel::parLapply(cl = cl, word_l, lexicon = lexicon,
get_nrc_values)
}
result_df <- as.data.frame(do.call(rbind, nrc_data), stringsAsFactors = F)
my_col_order <- c("anger", "anticipation", "disgust",
"fear", "joy", "sadness", "surprise",
"trust", "negative", "positive")
result_df[, my_col_order]
}
pre_ejemplo<-function (word_vector, language = "english", lexicon = T)
{
if (is.null(lexicon)) {
lexicon <- dplyr::filter_(nrc, ~lang == language)
}
data <- dplyr::filter_(lexicon, ~word %in% word_vector)
data <- dplyr::group_by_(data, ~sentiment)
data <- dplyr::summarise_at(data, "value", sum)
all_sent <- unique(lexicon$sentiment)
sent_present <- unique(data$sentiment)
sent_absent <- setdiff(all_sent, sent_present)
if (length(sent_absent) > 0) {
missing_data <- dplyr::data_frame(sentiment = sent_absent,
value = 0)
data <- rbind(data, missing_data)
}
tidyr::spread_(data, "sentiment", "value")
}
#ampliando el léxico del nrc
ww<-rbind(ww,c("spanish","racista", "negative", "1"))
ww<-rbind(ww,c("spanish","patético", "anger","1"))
ww<-rbind(ww,c("spanish","roban", "anger","1"))
ww<-rbind(ww,c("spanish","lacra", "anger","1"))
tail(ww)
#ejecutanto la nueva funcion
ejemplo(frase,language = "spanish")
ejemplo<-function (char_v, cl = NULL, language = "english",lexicon=T)
{
if (!is.character(char_v))
stop("Data must be a character vector.")
if (!is.null(cl) && !inherits(cl, "cluster"))
stop("Invalid Cluster")
lexicon <- dplyr::filter_(ww, ~lang == language)
word_l <- strsplit(tolower(char_v), "[^A-Za-z']+")
if (is.null(cl)) {
nrc_data <- lapply(word_l, get_nrc_values, lexicon = lexicon)
}
else {
nrc_data <- parallel::parLapply(cl = cl, word_l, lexicon = lexicon,
get_nrc_values)
}
result_df <- as.data.frame(do.call(rbind, nrc_data), stringsAsFactors = F)
my_col_order <- c("anger", "anticipation", "disgust",
"fear", "joy", "sadness", "surprise",
"trust", "negative", "positive")
result_df[, my_col_order]
}
pre_ejemplo<-function (word_vector, language = "english", lexicon = T)
{
if (is.null(lexicon)) {
lexicon <- dplyr::filter_(nrc, ~lang == language)
}
data <- dplyr::filter_(lexicon, ~word %in% word_vector)
data <- dplyr::group_by_(data, ~sentiment)
data <- dplyr::summarise_at(data, "value", sum)
all_sent <- unique(lexicon$sentiment)
sent_present <- unique(data$sentiment)
sent_absent <- setdiff(all_sent, sent_present)
if (length(sent_absent) > 0) {
missing_data <- dplyr::data_frame(sentiment = sent_absent,
value = 0)
data <- rbind(data, missing_data)
}
tidyr::spread_(data, "sentiment", "value")
}
#ampliando el léxico del nrc
ww<-rbind(ww,c("spanish","racista", "negative", "1"))
ww<-rbind(ww,c("spanish","patético", "anger","1"))
ww<-rbind(ww,c("spanish","roban", "anger","1"))
ww<-rbind(ww,c("spanish","lacra", "anger","1"))
tail(ww)
#ejecutanto la nueva funcion
ejemplo(frase,language = "spanish")
frase<-"Esa persona es racista, patético y una lacra. otros roban a las personas"
frase<-as.character(frase)
#resultado actual
library(syuzhet)
get_nrc_sentiment(frase,language = "spanish")
## anger anticipation disgust fear joy sadness surprise trust negative positive
## 1 0 0 0 0 0 0 0 0 0 0
#resultado esperado
#ejemplo(frase,language = "spanish")
## anger anticipation disgust fear joy sadness surprise trust negative positive
## 1 2 0 0 0 0 0 0 0 1 0
2
#####################################
ww<-get_sentiment_dictionary("nrc",language = "spanish")
get_nrc_sentiment
get_nrc_values
ejemplo<-function (char_v, cl = NULL, language = "english",lexicon=T)
{
if (!is.character(char_v))
stop("Data must be a character vector.")
if (!is.null(cl) && !inherits(cl, "cluster"))
stop("Invalid Cluster")
lexicon <- dplyr::filter_(ww, ~lang == language)
word_l <- strsplit(tolower(char_v), "[^A-Za-z']+")
if (is.null(cl)) {
nrc_data <- lapply(word_l, get_nrc_values, lexicon = lexicon)
}
else {
nrc_data <- parallel::parLapply(cl = cl, word_l, lexicon = lexicon,
get_nrc_values)
}
result_df <- as.data.frame(do.call(rbind, nrc_data), stringsAsFactors = F)
my_col_order <- c("anger", "anticipation", "disgust",
"fear", "joy", "sadness", "surprise",
"trust", "negative", "positive")
result_df[, my_col_order]
}
pre_ejemplo<-function (word_vector, language = "english", lexicon = T)
{
if (is.null(lexicon)) {
lexicon <- dplyr::filter_(nrc, ~lang == language)
}
data <- dplyr::filter_(lexicon, ~word %in% word_vector)
data <- dplyr::group_by_(data, ~sentiment)
data <- dplyr::summarise_at(data, "value", sum)
all_sent <- unique(lexicon$sentiment)
sent_present <- unique(data$sentiment)
sent_absent <- setdiff(all_sent, sent_present)
if (length(sent_absent) > 0) {
missing_data <- dplyr::data_frame(sentiment = sent_absent,
value = 0)
data <- rbind(data, missing_data)
}
tidyr::spread_(data, "sentiment", "value")
}
#ampliando el léxico del nrc
ww<-rbind(ww,c("spanish","racista", "negative", "1"))
ww<-rbind(ww,c("spanish","patético", "anger","1"))
ww<-rbind(ww,c("spanish","roban", "anger","1"))
ww<-rbind(ww,c("spanish","lacra", "anger","1"))
tail(ww)
#ejecutanto la nueva funcion
ejemplo(frase,language = "spanish")
install.packages("srvyr")
library(srvyr)
library(help=srvyr)
?as_survey_design()
library(parallel)
library(snow)
cl <- makeCluster(3, type = "SOCK")
teval(parApply(cl,mr,2,mean))
mr
#parApply(cl,mff[[1]],1,mean)
#parApply(cl,mbm,2,mean)
mr<-matrix(rnorm(10000),nrow = 1000)
parApply(cl,mr,2,mean)
#parApply(cl,mff[[1]],1,mean)
#parApply(cl,mbm,2,mean)
load("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-383\\data\\oct20.RData")
parApply(cl,computo$`MAS - IPSP`,sum)
parApply(cl,computo$`MAS - IPSP`,2,sum)
names(computp)
names(computo)
parApply(cl,computo[,15:25],2,sum)
80/2
40/7
52000/365
np=40,np(1-p)=4
1600/36
20**2
400/16
20/25
#binomial con n=25 y p=0.8
dbinom(0,25,0.8)
#binomial con n=25 y p=0.8
dbinom(1,25,0.8)
#binomial con n=25 y p=0.8
dbinom(2,25,0.8)
pbinom(6,25,0.8)
#binomial con n=25 y p=0.8
pbinom(6,25,0.8)
#binomial con n=25 y p=0.8
?pbinom(6,25,0.8)
#binomial con n=25 y p=0.8
pbinom(25,25,0.8)
#binomial con n=25 y p=0.8
pbinom(24,25,0.8)
#binomial con n=25 y p=0.8
1-pbinom(5,25,0.8)
pbinom(5,25,0.8)
#binomial con n=25 y p=0.8
1-pbinom(10,25,0.8)
25*0.8*0.2
#binomial con n=25 y p=0.8
dbinom(10,25,0.8)
8*0.6
10*0.6
10*0.6*0.4
#binomial con n=25 y p=0.8
dbinom(4,10,0.6)
dbinom(6,10,0.6)
10-2.4
100/7.6
6-2.4
#binomial con n=25 y p=0.8
dbinom(4,10,0.6)
dbinom(6,10,0.6)
dbinom(6,10,0.6)
#binomial con n=25 y p=0.8
dbinom(3,10,0.6)
dbinom(5,10,0.6)
#binomial con n=25 y p=0.8
dbinom(3,10,0.6)#a
dbinom(5,10,0.6)#b
pgeom(12,1/100)
pgeom(6,1/100)
(1/100)/0.99
pgeom(6,1/100)
pgeom(12,1/100)
?dhyper(5,10,24,)
dhyper(5,14,10,5)
dhyper(6,20,10,6)#a
dhyper(5,10,10,5)#b
ppois(2,4/5)#a
dpois(2,4/5)#a
ppois(2,4/5)#a
ppois(2,600/1100)#a
ppois(1,600/1100)#a
ppois(1,600/1100)#a
ppois(1,400/700)#b
ppois(1,600/1100)#a
ppois(1,600/1100)#a
ppois(1,400/700)#b
ppois(1,600/1100)#a
ppois(1,400/700)#b
dpois(0,400/700)#b
dpois(0,600/1100)#b
ppois(1,600/1100)#a
ppois(1,200/700)#b
ppois(1,100/700)#b
ppois(1,600/700)#b
ppois(1,700/700)#b
ppois(1,600/700)#b
ppois(1,600/1100)#a
ppois(1,600/700)#b
ppois(1,600/1100)#a
ppois(1,600/700)#b
ppois(1,600/1100)#a
ppois(1,600/700)#b
exp(-1)
1-pexp(8,1/8)
1-pexp(6,1/8)
1-pexp(4,1/8)
1-pexp(6,1/8)#a
1-pexp(4,1/8)#b
1-pexp(6,1/8)#a
1-pexp(4,1/8)#b
pnorm(1)
pnorm(3)
pnorm(1000,850,45)
pnorm(1000,850,45)-pnorm(800,850,45)
pnorm(900,850,45)-pnorm(800,850,45)
pnorm(900,850,45)
pnorm(800,850,45)
pnorm(950,850,45)-pnorm(750,850,45)#b
pnorm(910,850,45)-pnorm(790,850,45)#b
pnorm(900,850,45)-pnorm(800,850,45)#a
pnorm(910,850,45)-pnorm(790,850,45)#b
pnorm(900,850,45)-pnorm(800,850,45)#a
pnorm(910,850,45)-pnorm(790,850,45)#b
pnorm(910,850,45)-pnorm(790,850,45)#b
pnorm(900,850,45)-pnorm(800,850,45)#a
pnorm(910,850,45)-pnorm(790,850,45)#b
1-pnorm(45,50,4)
1-pnorm(45,45,6)
1-pnorm(45,50,4)
1-pnorm(45,45,6)
1-pnorm(45,50,4)
1-pnorm(45,45,6)
1-pnorm(45,45,6)
1-pnorm(45,50,4)
1-pnorm(45,45,6)
3500000*1000
(3500000*1000)/7
round((3500000*1000)/7)
(3500000*1000)/7
(3500000*1000)/7
((3500000*1000)/7)/1000
((3500000*1000)/7)/100000
(3500000*1000)/7
((3500000*1000)/7)/310000000
((3500000*1000)/7)/1500000000
setwd(""C:\\Users\\ALVARO\\Documents\\GitHub\\EST-383\\data\\")
setwd("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-383\\data\\")
dir()
knitr::opts_chunk$set(echo = TRUE)
load("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-383\\data\\endsa.RData")
names(endsa)
attributes(endsa)
dir()
load("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-383\\data\\eh18.Rdata")
names(eh18p)
unique(eh18p$tipohogar)
attributes(eh19p)
ww<-attributes(eh18p)
ww$variable.labels[447]
