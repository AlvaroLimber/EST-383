---
title: "Solucionario: Segundo Parcial (30pts)"
subtitle: "Programacion Estadística I"
author: "Lic. Alvaro Chirino Gutierrez"
date: "17/7/2020"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Pregunta 1 (5 pts)

* (1pts) Describa la diferencia entre los procesos de inferencia: descriptiva, causal y predictivo 

Resp. La inferencia descriptivo esta orientada a la estimación de parámetros, la causal en encontrar la medida asociada entre la relación de una variable con respecto otra (x -> y) y la predictiva, a partir de un modelo en base a variables independientes predecir el comportamiento de variables dependientes.

* (1pts) De un ejemplo de record linkage

Resp. El identificador de una persona CI, el identificador de un municipio, etc.  

* (2pts) Describa los errores de fila, columna y celda

Resp.
  + Errores fila: **Omisión** Elementos de la población objetivo no son parte de la base., **Duplicados** Algunos elementos de la población ocupan mas de una fila en la base de datos, **Errores en la inclusión** Algunas filas contienen elementos o entidades que no forman parte de la población objetivo.
  + Errores columna: Inadecuado o errónea asignación de la etiqueta de la variable o los valores de la variable. 
  + Errores celda: **Error de contenido** ocurre cuando el valor cumple las condiciones de la columna pero se aleja bastante de los valores esperados, **especificación** la celda contiene informacion no correspondiente a la columna,  **valor perdido** celdas vacias donde se esperaba tener información.

* (1pts) Describa los errores asociados a las 3 V en big data

Resp. Asumiendo completa veracidad. Las 3 V; Volumen, Velocidad y Variedad pueden generar problemas relacionados a correlacion espuria y endogeneidad accidental.

# Pregunta 2 (10 pts)

```{r,echo=F}
load("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-383\\data\\oct20.RData")
```

* (5pts) Usando la base de datos de computo para las elecciones del 20 de octubre de 2019:

Solución,

```{r}
rm(list=ls())
# 1. Cargue la base en R
load("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-383\\data\\oct20.RData")
#2. Guarde la base en csv
setwd("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-383\\parciales")
write.csv(computo,"computo.csv")
#3. Cargue el csv como un objeto ffdf. Con el nombre bd1.
library(ffbase)
library(ff)
system("mkdir ffdf")
options(fftempdir="C:\\Users\\ALVARO\\Documents\\GitHub\\EST-383\\parciales\\ffdf")
bd1<-read.csv.ffdf(file="computo.csv",sep=",",header=T,colClasses=NA)
# 4. Sobre el objeto bd1 obtenga una tabla de departamento vs. tipo de elección
head(table(bd1$Departamento,bd1$Elección))
# 5. Repita el paso 4 con una base obtenida con el comando as.ffdf o as.data.frame.ffdf
bd2<-as.data.frame(bd1)
bd2<-as.ffdf(bd2)
head(table(bd2$Departamento,bd2$Elección))
#otra alternativa
aux<-sapply(computo,is.character)#character a factor
for(i in names(computo)){
  if(aux[i]==T){
    computo[,i]<-as.factor(computo[,i])
  }
}
bd3<-as.ffdf(computo)
head(table(bd3$Departamento,bd3$Elección))
```

* (5pts) Usando la base de datos de computo para las elecciones del 20 de octubre de 2019. Seleccione solo Bolivia y las elecciones de presidente y vicepresidente. 
  
Solución, 

```{r,echo=F,message=F}
rm(list = ls())
library(dplyr)
#evaluación del tiempo
teval<-function(...){
  gc()
  start<-proc.time()
  result<-eval(...)
  finish<-proc.time()
  return(list(Duration=finish-start,Result=result))
  }
########################
load("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-383\\data\\oct20.RData")
aux<- computo %>% filter(País=="Bolivia" & Elección=="Presidente y Vicepresidente")
# Compare el tiempo de ejecución entre el código nativo de R y usando la librería parallel. Para obtener la suma de votos de las variables:"
# R nativo
teval(apply(aux[,13:25],2,sum))
# parallel
library(parallel)
library(snow)
cl <- makeCluster(3, type = "SOCK")
teval(parApply(cl,aux[,14:25],2,mean))
stopCluster(cl)
```


# Pregunta 3 (15 pts)

* (5 pts) Usando la encuesta de hogares defina una base de datos que contenga las siguientes variables para los jefes de hogar:
  + Edad
  + Sexo 
  + Ingreso laboral
  + Departamento 
  + Años de educación
  + Área
  + Incidencia de pobreza moderada (p0)
  + Acceso a internet en el hogar
  + Vivienda propia y totalmente pagada
  + Número de miembros en el hogar

(Sugerencia: Use la variable folio y el comando merge para unir bases)

Solución,

```{r}
rm(list=ls())
load(url("https://github.com/AlvaroLimber/EST-383/raw/master/data/eh18.Rdata"))
#jefe/a del hogar
jefe<-eh18p %>% filter(s02a_05==unique(eh18p$s02a_05)[1]) %>% select(folio,s02a_02,s02a_03,ylab,depto,aestudio,area,p0)
#variables en la vivienda
vv<-eh18v %>% mutate(internet=s01a_31=="1. Si", vpropia=(s01a_02== unique(eh18v$s01a_02)[1])) %>% select(folio,internet,vpropia)
#miembros
mm<-eh18p %>% mutate(miembros=1) %>% group_by(folio) %>% summarise(miembros=sum(miembros))
#base consolidada
jefe<-merge(jefe,mm)
jefe<-merge(jefe,vv)
head(jefe)
```

* (10 pts) Para la base alojada en R y la base alojada en Spark, genere lo siguiente: 

```{r}
rm(eh18p,eh18v,mm,vv)
library(sparklyr)
sc<-spark_connect(master="local")
sp_jefe<-copy_to(sc,jefe,"eh18")
# Promedio de años de educación del jefe del hogar por departamento y Área 
#R
jefe %>% group_by(depto,area) %>% summarise(mean(aestudio,na.rm=T))
#Spark
sp_jefe %>% group_by(depto,area) %>% summarise(mean(aestudio))
# Proporción de jefes del hogar con un ingreso laboral superior a 4000 Bs. Por Departamento y Sexo 
#R
jefe %>% mutate(pp=ylab>4000) %>% group_by(depto,s02a_02) %>% summarise(mean(pp,na.rm=T))
#Spark
sp_jefe %>% mutate(pp=ifelse(ylab>4000,1,0)) %>% group_by(depto,s02a_02) %>% summarise(mean(pp))
# Proporción de pobreza moderada en hogares con jefes de hogar de 30 años o menos por sexo 
jefe %>% mutate(p0=ifelse(p0=="Pobre",1,0)) %>% filter(s02a_03<=30) %>% group_by(s02a_02)%>% summarise(mean(p0))
sp_jefe %>% mutate(p0=ifelse(p0=="Pobre",1,0)) %>% filter(s02a_03<=30) %>% group_by(s02a_02)%>% summarise(mean(p0))
# Promedio de miembros en el hogar por departamento, área y sexo del jefe del hogar
jefe %>% group_by(depto,area,s02a_02) %>% summarise(mean(miembros))
sp_jefe %>% group_by(depto,area,s02a_02) %>% summarise(mean(miembros))
# Gráfico sobre el acceso al internet por departamento (ggplot)
library(ggplot2)
ggplot(jefe,aes(internet))+geom_bar()+facet_wrap(~depto)
ggplot(sp_jefe,aes(internet))+geom_bar()+facet_wrap(~depto)
spark_disconnect(sc)
```
