library( syuzhet )
aa <- get_nrc_sentiment ( bd3 $ texto , idioma  =  " español " )
library(syuzhet)
library(rtweet)
#Frase
frase<-"Esa persona es racista, patético y una lacra. otros roban a las personas"
#Generando el léxico en español
lex<-get_sentiment_dictionary("nrc",language = "spanish")
#Ampliando el léxico
lex<-rbind(lex,c("spanish","racista","negative","1"))
lex<-rbind(lex,c("spanish","patético","anger","1"))
lex<-rbind(lex,c("spanish","roban","anger","1"))
lex<-rbind(lex,c("spanish","lacra","anger","1"))
tail(lex)
#Creando la función para obtener la tabla de sentimientos
obtener_sentimientos<-function (char_v, lex, cl = NULL, language = "spanish")
{
if (!is.character(char_v))
stop("Data must be a character vector.")
if (!is.null(cl) && !inherits(cl, "cluster"))
stop("Invalid Cluster")
lex$value = as.double(lex$value)
word_l <- strsplit(tolower(char_v), "[^A-Za-z']+")
if (is.null(cl)) {
nrc_data <- lapply(word_l, get_nrc_values, language = language, lexicon = lex)
}
else {
nrc_data <- parallel::parLapply(cl = cl, word_l, language = language,lexicon = lex,
get_nrc_values)
}
result_df <- as.data.frame(do.call(rbind, nrc_data), stringsAsFactors = F)
my_col_order <- c("anger", "anticipation", "disgust",
"fear", "joy", "sadness", "surprise",
"trust", "negative", "positive")
result_df[, my_col_order]
}
#Resultado Actual
get_nrc_sentiment(frase,language = "spanish")
#Resultado Con la Funcion
obtener_sentimientos(frase, lex, language = "spanish")
rm(list=ls())
load(url("https://github.com/AlvaroLimber/EST-384/raw/master/data/endsa.RData"))
library(dplyr)
bd2<-endsa %>% filter(edad>=20 & edad<=40)
attributes(endsa)
str(endsa)
table(bd2[,15])
str(bd2)
bd2<-bd2[,c(3,6,7,10,11,12,13,14,15,16,23)]
bd2<-na.omit(bd2)
bd2_2<-bd2
#aux<-c(  "depto",  "area" ,  "year" ,  "edad" ,  "sexo" ,  "ae01",
# "ae02"  , "ae03"  , "ae04"  , "ae05"  , "ae06"  , "ae07"  , "ae08",
#"ae09" )
#for(i in aux){
# bd2[[i]]<-bd2[[i]]==1
#}
str(bd2)
table(bd2$ae09)
#table(bd2$vf10)
#base de test y entrenamiento
set.seed(123)
index = sample(1:2, nrow(bd2), replace = TRUE, prob=c(0.7, 0.3))
prop.table(table(index))
trainbd_l<-bd2[index==1,]
testbd_l<-bd2[index==2,]
m1l<-glm(ae09~.,data=trainbd_l,family = binomial(link="logit"))
m2l<-step(m1l)
summary(m2l)
clase_l<-predict(m2l,testbd_l,type="response")>0.5
table(clase_l)
table(testbd_l$ae09,clase_l)
table(testbd_l$ae09,clase_l)
library(caret)
confusionMatrix(table(testbd_l$ae09,clase_l))
frase<-"Esa persona es racista, patético y una lacra. otros roban a las personas"
get_nrc_sentiment(frase,language = "spanish")
#####################################
ww<-get_sentiment_dictionary("nrc",language = "spanish")
get_nrc_sentiment
get_nrc_values
ejemplo<-function (char_v, cl = NULL, language = "english",lexicon=T)
{
if (!is.character(char_v))
stop("Data must be a character vector.")
if (!is.null(cl) && !inherits(cl, "cluster"))
stop("Invalid Cluster")
lexicon <- dplyr::filter_(ww, ~lang == language)
word_l <- strsplit(tolower(char_v), "[^A-Za-z']+")
if (is.null(cl)) {
nrc_data <- lapply(word_l, get_nrc_values, lexicon = lexicon)
}
else {
nrc_data <- parallel::parLapply(cl = cl, word_l, lexicon = lexicon,
get_nrc_values)
}
result_df <- as.data.frame(do.call(rbind, nrc_data), stringsAsFactors = F)
my_col_order <- c("anger", "anticipation", "disgust",
"fear", "joy", "sadness", "surprise",
"trust", "negative", "positive")
result_df[, my_col_order]
}
pre_ejemplo<-function (word_vector, language = "english", lexicon = T)
{
if (is.null(lexicon)) {
lexicon <- dplyr::filter_(nrc, ~lang == language)
}
data <- dplyr::filter_(lexicon, ~word %in% word_vector)
data <- dplyr::group_by_(data, ~sentiment)
data <- dplyr::summarise_at(data, "value", sum)
all_sent <- unique(lexicon$sentiment)
sent_present <- unique(data$sentiment)
sent_absent <- setdiff(all_sent, sent_present)
if (length(sent_absent) > 0) {
missing_data <- dplyr::data_frame(sentiment = sent_absent,
value = 0)
data <- rbind(data, missing_data)
}
tidyr::spread_(data, "sentiment", "value")
}
#ampliando el léxico del nrc
ww<-rbind(ww,c("spanish","racista", "negative", "1"))
ww<-rbind(ww,c("spanish","patético", "anger","1"))
ww<-rbind(ww,c("spanish","roban", "anger","1"))
ww<-rbind(ww,c("spanish","lacra", "anger","1"))
tail(ww)
#ejecutanto la nueva funcion
ejemplo(frase,language = "spanish")
ejemplo<-function (char_v, cl = NULL, language = "english",lexicon=T)
{
if (!is.character(char_v))
stop("Data must be a character vector.")
if (!is.null(cl) && !inherits(cl, "cluster"))
stop("Invalid Cluster")
lexicon <- dplyr::filter_(ww, ~lang == language)
word_l <- strsplit(tolower(char_v), "[^A-Za-z']+")
if (is.null(cl)) {
nrc_data <- lapply(word_l, get_nrc_values, lexicon = lexicon)
}
else {
nrc_data <- parallel::parLapply(cl = cl, word_l, lexicon = lexicon,
get_nrc_values)
}
result_df <- as.data.frame(do.call(rbind, nrc_data), stringsAsFactors = F)
my_col_order <- c("anger", "anticipation", "disgust",
"fear", "joy", "sadness", "surprise",
"trust", "negative", "positive")
result_df[, my_col_order]
}
pre_ejemplo<-function (word_vector, language = "english", lexicon = T)
{
if (is.null(lexicon)) {
lexicon <- dplyr::filter_(nrc, ~lang == language)
}
data <- dplyr::filter_(lexicon, ~word %in% word_vector)
data <- dplyr::group_by_(data, ~sentiment)
data <- dplyr::summarise_at(data, "value", sum)
all_sent <- unique(lexicon$sentiment)
sent_present <- unique(data$sentiment)
sent_absent <- setdiff(all_sent, sent_present)
if (length(sent_absent) > 0) {
missing_data <- dplyr::data_frame(sentiment = sent_absent,
value = 0)
data <- rbind(data, missing_data)
}
tidyr::spread_(data, "sentiment", "value")
}
#ampliando el léxico del nrc
ww<-rbind(ww,c("spanish","racista", "negative", "1"))
ww<-rbind(ww,c("spanish","patético", "anger","1"))
ww<-rbind(ww,c("spanish","roban", "anger","1"))
ww<-rbind(ww,c("spanish","lacra", "anger","1"))
tail(ww)
#ejecutanto la nueva funcion
ejemplo(frase,language = "spanish")
frase<-"Esa persona es racista, patético y una lacra. otros roban a las personas"
frase<-as.character(frase)
#resultado actual
library(syuzhet)
get_nrc_sentiment(frase,language = "spanish")
## anger anticipation disgust fear joy sadness surprise trust negative positive
## 1 0 0 0 0 0 0 0 0 0 0
#resultado esperado
#ejemplo(frase,language = "spanish")
## anger anticipation disgust fear joy sadness surprise trust negative positive
## 1 2 0 0 0 0 0 0 0 1 0
2
#####################################
ww<-get_sentiment_dictionary("nrc",language = "spanish")
get_nrc_sentiment
get_nrc_values
ejemplo<-function (char_v, cl = NULL, language = "english",lexicon=T)
{
if (!is.character(char_v))
stop("Data must be a character vector.")
if (!is.null(cl) && !inherits(cl, "cluster"))
stop("Invalid Cluster")
lexicon <- dplyr::filter_(ww, ~lang == language)
word_l <- strsplit(tolower(char_v), "[^A-Za-z']+")
if (is.null(cl)) {
nrc_data <- lapply(word_l, get_nrc_values, lexicon = lexicon)
}
else {
nrc_data <- parallel::parLapply(cl = cl, word_l, lexicon = lexicon,
get_nrc_values)
}
result_df <- as.data.frame(do.call(rbind, nrc_data), stringsAsFactors = F)
my_col_order <- c("anger", "anticipation", "disgust",
"fear", "joy", "sadness", "surprise",
"trust", "negative", "positive")
result_df[, my_col_order]
}
pre_ejemplo<-function (word_vector, language = "english", lexicon = T)
{
if (is.null(lexicon)) {
lexicon <- dplyr::filter_(nrc, ~lang == language)
}
data <- dplyr::filter_(lexicon, ~word %in% word_vector)
data <- dplyr::group_by_(data, ~sentiment)
data <- dplyr::summarise_at(data, "value", sum)
all_sent <- unique(lexicon$sentiment)
sent_present <- unique(data$sentiment)
sent_absent <- setdiff(all_sent, sent_present)
if (length(sent_absent) > 0) {
missing_data <- dplyr::data_frame(sentiment = sent_absent,
value = 0)
data <- rbind(data, missing_data)
}
tidyr::spread_(data, "sentiment", "value")
}
#ampliando el léxico del nrc
ww<-rbind(ww,c("spanish","racista", "negative", "1"))
ww<-rbind(ww,c("spanish","patético", "anger","1"))
ww<-rbind(ww,c("spanish","roban", "anger","1"))
ww<-rbind(ww,c("spanish","lacra", "anger","1"))
tail(ww)
#ejecutanto la nueva funcion
ejemplo(frase,language = "spanish")
install.packages("srvyr")
library(srvyr)
library(help=srvyr)
?as_survey_design()
library(parallel)
library(snow)
cl <- makeCluster(3, type = "SOCK")
teval(parApply(cl,mr,2,mean))
mr
#parApply(cl,mff[[1]],1,mean)
#parApply(cl,mbm,2,mean)
mr<-matrix(rnorm(10000),nrow = 1000)
parApply(cl,mr,2,mean)
#parApply(cl,mff[[1]],1,mean)
#parApply(cl,mbm,2,mean)
load("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-383\\data\\oct20.RData")
parApply(cl,computo$`MAS - IPSP`,sum)
parApply(cl,computo$`MAS - IPSP`,2,sum)
names(computp)
names(computo)
parApply(cl,computo[,15:25],2,sum)
80/2
40/7
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
load("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-383\\data\\oct20.RData")
rm(list=ls())
# 1. Cargue la base en R
load("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-383\\data\\oct20.RData")
#2. Guarde la base en csv
write.csv(,computo,"computo.csv")
#2. Guarde la base en csv
write.csv(computo,"computo.csv")
#2. Guarde la base en csv
write.csv(computo,"computo.csv")
3.
dir()
#3. Cargue el csv como un objeto ffdf. Con el nombre bd1.
library(ffdf)
library(ff)
#3. Cargue el csv como un objeto ffdf. Con el nombre bd1.
library(ffdf)
#3. Cargue el csv como un objeto ffdf. Con el nombre bd1.
library(ffdf)
install.packages("ffdf")
#2. Guarde la base en csv
setwd("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-383\\parciales")
#3. Cargue el csv como un objeto ffdf. Con el nombre bd1.
library(ffbase)
system("mkdir ffdf")
options(fftempdir="C:\\Users\\ALVARO\\Documents\\GitHub\\EST-383\\parciales\\ffdf")
?write.csv(computo,"computo.csv")
?write.csv
bd1<-read.csv.ffdf(file="computo.csv",sep=",",header=T,colClasses=NA)
#4. Sobre el objeto bd1 obtenga una tabla de departamento vs. tipo de elección
table(bd1$Departamento,bd1$Elección)
# 4. Sobre el objeto bd1 obtenga una tabla de departamento vs. tipo de elección
head(table(bd1$Departamento,bd1$Elección))
# 5. Repita el paso 4 con una base obtenida con el comando as.ffdf o as.data.frame.ffdf
bd2<-as.ffdf(computo)
# 5. Repita el paso 4 con una base obtenida con el comando as.ffdf o as.data.frame.ffdf
bd2<-as.data.frame.ffdf(computo)
# 5. Repita el paso 4 con una base obtenida con el comando as.ffdf o as.data.frame.ffdf
bd2<-as.ffdf(computo)
# 5. Repita el paso 4 con una base obtenida con el comando as.ffdf o as.data.frame.ffdf
bd2<-as.ff(computo)
?as.ffdf
data.frame(computo)
bd2<-data.frame(computo)
# 5. Repita el paso 4 con una base obtenida con el comando as.ffdf o as.data.frame.ffdf
bd2<-as.ffdf(computo)
# 5. Repita el paso 4 con una base obtenida con el comando as.ffdf o as.data.frame.ffdf
bd2<-as.ffdf(as.data.frame.ffdf(computo))
# 5. Repita el paso 4 con una base obtenida con el comando as.ffdf o as.data.frame.ffdf
as.ffdf(computo)
# 5. Repita el paso 4 con una base obtenida con el comando as.ffdf o as.data.frame.ffdf
as.ffdf(computo)
?as.ff()
str(bd1)
str(computo)
bd1$País
class(bd1$País)
# 5. Repita el paso 4 con una base obtenida con el comando as.ffdf o as.data.frame.ffdf
as.ffdf(computo)
# 5. Repita el paso 4 con una base obtenida con el comando as.ffdf o as.data.frame.ffdf
as.data.frame(bd2)
# 5. Repita el paso 4 con una base obtenida con el comando as.ffdf o as.data.frame.ffdf
as.data.frame(bd1)
# 5. Repita el paso 4 con una base obtenida con el comando as.ffdf o as.data.frame.ffdf
bd2<-as.data.frame(bd1)
str(bd2)
as.ffdf(bd2)
bd2<-as.ffdf(bd2)
#otra alternativa
class(computo)
#otra alternativa
class(computo[[1]])
#otra alternativa
sapply(computo,is.character)
#otra alternativa
aux<-sapply(computo,is.character)#character a factor
computo[,aux]
sapply(computo[,aux],as.factor)
computo[,aux]<-sapply(computo[,aux],as.factor)
str(computo)
#otra alternativa
aux<-sapply(computo,is.character)#character a factor
?unclass()
#otra alternativa
aux<-sapply(computo,is.character)#character a factor
for(i in names(computo)){
if(aux[i]==T){
computo[,i]<-as.factor(computo[,i])
}
}
str(computo)
as.ffdf(computo)
# 5. Repita el paso 4 con una base obtenida con el comando as.ffdf o as.data.frame.ffdf
bd2<-as.data.frame(bd1)
bd2<-as.ffdf(bd2)
head(table(bd2$Departamento,bd2$Elección))
#otra alternativa
aux<-sapply(computo,is.character)#character a factor
for(i in names(computo)){
if(aux[i]==T){
computo[,i]<-as.factor(computo[,i])
}
}
bd3<-as.ffdf(computo)
head(table(bd3$Departamento,bd3$Elección))
rm(list = ls())
library(dplyr)
library(parallel)
load("C:\\Users\\ALVARO\\Documents\\GitHub\\EST-383\\data\\oct20.RData")
aux<- computo %>% filter(País=="Bolivia" & Elección=="Presidente y Vicepresidente")
apply(aux[,13:25],2,sum)
#evaluación del tiempo
teval<-function(...){
gc()
start<-proc.time()
result<-eval(...)
finish<-proc.time()
return(list(Duration=finish-start,Result=result))
}
teval(apply(aux[,13:25],2,sum))
# parallel
library(parallel)
library(snow)
cl <- makeCluster(3, type = "SOCK")
teval(parApply(cl,aux[,14:25],2,mean))
# Compare el tiempo de ejecución entre el código nativo de R y usando la librería parallel. Para obtener la suma de votos de las variables:"
# R nativo
teval(apply(aux[,13:25],2,sum))
teval(parApply(cl,aux[,14:25],2,mean))
stopCluster(cl)
load(url("https://github.com/AlvaroLimber/EST-383/raw/master/data/eh18.Rdata"))
rm(list=ls())
load(url("https://github.com/AlvaroLimber/EST-383/raw/master/data/eh18.Rdata"))
#jefe/a del hogar
jefe<-eh18p %>% filter(s02a_05==unique(eh18p$s02a_05)[1]) %>% select(folio,s02a_02,s02a_03,depto,area,aestudio,p0,ylab)
#jefe/a del hogar
jefe<-eh18p %>% filter(s02a_05==unique(eh18p$s02a_05)[1]) %>% select(folio,s02a_02,s02a_03,ylab,depto,aestudio,area,p0)
names(eh18v)
names(eh18p)
attributes(eh18p)$
attributes(eh18p)
attributes(eh18v)
unique(eh18v$s01a_31)
s01a_02
eh18v$s01a_02
unique(eh18v$s01a_02)
#variables en la vivienda
vv<-eh18v %>% mutate(internet=s01a_31=="1. Si", vpropia=(s01a_02 %in% unique(eh18v$s01a_02)[1:2])) %>% select(folio,internet,vpropia)
head(vv)
#variables en la vivienda
vv<-eh18v %>% mutate(internet=s01a_31=="1. Si", vpropia=(s01a_02 %in% unique(eh18v$s01a_02)[1:2])) %>% select(folio,internet,vpropia,s01a_02)
head(vv)
head(vv,20)
#variables en la vivienda
vv<-eh18v %>% mutate(internet=s01a_31=="1. Si", vpropia=(s01a_02== unique(eh18v$s01a_02)[1])) %>% select(folio,internet,vpropia,s01a_02)
vv
#miembros
eh18p %>% group_by(folio) %>% summarise(miembros=sum(1))
#miembros
eh18p %>% mutate(miembros=1) %>% group_by(folio) %>% summarise(miembros=sum(miembros))
#miembros
mm<-eh18p %>% mutate(miembros=1) %>% group_by(folio) %>% summarise(miembros=sum(miembros))
#base consolidada
jefe<-merge(jefe,mm)
jefe<-merge(jefe,vv)
#base consolidada
jefe<-merge(jefe,mm)
rm(list=ls())
load(url("https://github.com/AlvaroLimber/EST-383/raw/master/data/eh18.Rdata"))
#jefe/a del hogar
jefe<-eh18p %>% filter(s02a_05==unique(eh18p$s02a_05)[1]) %>% select(folio,s02a_02,s02a_03,ylab,depto,aestudio,area,p0)
#variables en la vivienda
vv<-eh18v %>% mutate(internet=s01a_31=="1. Si", vpropia=(s01a_02== unique(eh18v$s01a_02)[1])) %>% select(folio,internet,vpropia)
#miembros
mm<-eh18p %>% mutate(miembros=1) %>% group_by(folio) %>% summarise(miembros=sum(miembros))
#base consolidada
jefe<-merge(jefe,mm)
jefe<-merge(jefe,vv)
head(jefe)
rm(eh18p,eh18v,mm,vv)
library(sparklyr)
sc<-spark_connect(master="local")
sp_jefe<-copy_to(sc,jefe,"eh18")
# Promedio de años de educación del jefe del hogar por departamento y Área
jefe %>% group_by(depto,area) %>% summarise(mean(aestudio))
# Promedio de años de educación del jefe del hogar por departamento y Área
jefe %>% group_by(depto,area) %>% summarise(mean(aestudio),na.rm=T)
# Promedio de años de educación del jefe del hogar por departamento y Área
jefe %>% group_by(depto,area) %>% summarise(mean(aestudio,na.rm=T))
sp_jefe %>% group_by(depto,ares) %>% summarise(mean(aestudio,na.rm=T))
sp_jefe %>% group_by(depto,area) %>% summarise(mean(aestudio,na.rm=T))
sp_jefe %>% group_by(depto,area) %>% summarise(mean(aestudio))
sp_jefe %>% group_by(depto,area) %>% summarise(mean(aestudio,na.rm = TRUE))
sp_jefe %>% group_by(depto,area) %>% summarise(mean(aestudio,na.rm = TRUE))
sp_jefe %>% group_by(depto,area) %>% summarise(mean(aestudio))
# Promedio de años de educación del jefe del hogar por departamento y Área
jefe %>% group_by(depto,area) %>% summarise(mean(aestudio,na.rm=T))
sp_jefe %>% group_by(depto,area) %>% summarise(mean(aestudio))
# Proporción de jefes del hogar con un ingreso laboral superior a 4000 Bs. Por Departamento y Sexo
jefe %>% mutate(pp=ylab>400) %>% group_by(depto,area) %>% summarise(mean(pp))
# Proporción de jefes del hogar con un ingreso laboral superior a 4000 Bs. Por Departamento y Sexo
jefe %>% mutate(pp=ylab>400) %>% group_by(depto,area) %>% summarise(mean(pp,na.rm=T))
# Proporción de jefes del hogar con un ingreso laboral superior a 4000 Bs. Por Departamento y Sexo
jefe %>% mutate(pp=ylab>400) %>% group_by(depto,s02a_02) %>% summarise(mean(pp,na.rm=T))
# Proporción de jefes del hogar con un ingreso laboral superior a 4000 Bs. Por Departamento y Sexo
jefe %>% mutate(pp=ylab>4000) %>% group_by(depto,s02a_02) %>% summarise(mean(pp,na.rm=T))
sp_jefe %>% mutate(pp=ifelse(ylab>4000,1,0)) %>% group_by(depto,s02a_02) %>% summarise(mean(pp,na.rm=T))
ifelse(ylab>4000,1,0)
ifelse(jefe$ylab>4000,1,0)
sp_jefe %>% mutate(pp=ifelse(ylab>4000,1,0)) %>% group_by(depto,s02a_02) %>% summarise(mean(pp))
sp_jefe %>% mutate(pp=ifelse(ylab>4000,1,0)) %>% group_by(depto,s02a_02) %>% summarise(mean(pp))
# Proporción de jefes del hogar con un ingreso laboral superior a 4000 Bs. Por Departamento y Sexo
jefe %>% mutate(pp=ylab>4000) %>% group_by(depto,s02a_02) %>% summarise(mean(pp,na.rm=T))
sp_jefe %>% mutate(pp=ifelse(ylab>4000,1,0)) %>% group_by(depto,s02a_02) %>% summarise(mean(pp))
# Proporción de pobreza moderada en hogares con jefes de hogar de 30 años o menos por sexo
jefe %>% filter(s02a_03<=30) %>% group_by(s02a_02)%>% summarise(mean(p0))
jefe$p0
mean(jefe$p0)
# Proporción de pobreza moderada en hogares con jefes de hogar de 30 años o menos por sexo
jefe %>% mutate(p0=ifelse(p0=="Pobre",1,0)) %>% filter(s02a_03<=30) %>% group_by(s02a_02)%>% summarise(mean(p0))
sp_jefe %>% mutate(p0=ifelse(p0=="Pobre",1,0)) %>% filter(s02a_03<=30) %>% group_by(s02a_02)%>% summarise(mean(p0))
# Promedio de miembros en el hogar por departamento, área y sexo del jefe del hogar
jefe %>% group_by(depto,area,s02a_02) %>% summarise(mean(miembros))
sp_jefe %>% group_by(depto,area,s02a_02) %>% summarise(mean(miembros))
# Gráfico sobre el acceso al internet por departamento (ggplot)
library(ggplot2)
ggplot(jefe,aes(depto,internet))+geom_bar()
ggplot(jefe,aes(x=depto,y=internet))+geom_bar()
ggplot(jefe,aes(x=depto,y=internet))+geom_bar(internet)
jefe
names(jefe)
ggplot(jefe,aes(x=depto,y=internet))+geom_bar()
ggplot(jefe)+geom_bar(aes(x=depto,y=internet))
ggplot(jefe,aes(internet))+geom_bar()
ggplot(jefe,aes(x=depto,y=internet))+geom_bar()
ggplot(jefe,aes(x=depto,y=internet))+geom_bar(position = "doge")
ggplot(jefe,aes(x=depto,y=internet))+geom_bar(position = "dogge")
ggplot(jefe,aes(x=depto,y=internet))+geom_bar(position = "dodge")
ggplot(jefe,aes(x=depto))+geom_bar(position = "dodge")
ggplot(jefe,aes(x=depto))+geom_bar(aes(y=internet),position = "dodge")
ggplot(jefe,aes(internet))+geom_bar()
ggplot(jefe,aes(internet))+geom_bar()+facet_wrap(depto)
ggplot(jefe,aes(internet))+geom_bar()+facet_wrap(~depto)
ggplot(sp_jefe,aes(internet))+geom_bar()+facet_wrap(~depto)
ggplot(jefe,aes(internet))+geom_bar(aes(y = (..count..)/sum(..count..)))+facet_wrap(~depto)
ggplot(jefe,aes(internet))+geom_bar(aes(y =100*( (..count..)/sum(..count..))))+facet_wrap(~depto)
ggplot(jefe,aes(internet))+geom_bar((y = ..prop..)+facet_wrap(~depto)
ggplot(jefe,aes(internet))+geom_bar((y = ..prop..))+facet_wrap(~depto)
spark_disconnect(sc)
