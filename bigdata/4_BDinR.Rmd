# Big Data en R 
[comment]: <> (Principalmente Big Data Analytics with R, Simon Walkowiak capitulo 3)

R en un software que se adapta perfectamente con las fases del ciclo de vida de los proyectos de datos, ofreciendo herramientas para cada una de ellas; Entre las mas interesantes, R Markdown, Shiny, sweave, etc.

Adicionalmente existen multiples librerias que permite trabajar con otros software, principalmente los asociados a bases de datos.

![](images/r1.png)

En el capitulo 1 se enfatiza el uso de R para el manejo, procesamiento y análisis de bases de datos, sumado a esto el conocimiento de distintas estadísticas en base a los cursos de formación, en este capitulo se buscar unir ambos topicos y explicar como usar el poder del modelado matematico y de datos en R, considerando bases de datos **grandes**, esto sin necesidad de recurrir a otros equipos. 

Lo que se espera a partir de este capitulo es: 

* Conocer las limitaciones de R para el Big Data y como ellas pueden resolverse
* El uso de las librerias ff, ffbase, ffbase2, y bigmemory, para el manejo de la memoria del equipo
* El uso de metodos estadisticos para objetos grandes en R, atraves de las librerias bigglm y ffbase
* Mejorar la velocidad del procesamiento de datos con librerias que permiten la computación paralela (parallel computing)
* Manipulación de datos más rápidos con el uso de la libreria data.table

## Limitaciones en R
A manera que uno va aprendiendo mas del R en la universidad o en el trabajo se valora cada vez mas la flexibilidad de R, su constante crecimiento, la ventaja de ser de codigo abierto, etc. Sin embargo, es importante tener en cuenta las limitaciones de R:

* Los datos se ajustan a la RAM
* R es generalmente muy lento comparado con otros lenguajes

### Memoria

  * R permite trabajar con bases de datos que no superen el 50-60% de la RAM de la computadora
  * Existen soluciones en R sin tener que recurrir aun a plataformas como; Microsoft Azure, Amazon EC2, or
Google Cloud Platform.
  * Existe tambien la opción de trabajar con RStudio-Cloud, https://rstudio.cloud/plans/free

### Velocidad de procesamiento

  1. R se considera un lenguaje interpretado y, como tal, su ejecución de código más lenta viene por definición.
  2. Procesos linea por linea 
  3. El bajo rendimiento del código R puede deberse al hecho de que el lenguaje no está formalmente definido

## A los límites de la memoria y más allá

### Transformacion y agregación de datos con la librería ff y ffbase 

```{r,eval=F}
install.packages("ff")
install.packages("ffbase")
#install.packages("ffbase2") / github
```

```{r,eval=FALSE}
library(help=ff)
library(ffbase)
setwd("C:\\Users\\ALVARO\\Desktop\\db_bolivia\\bigdata")
bd1<-read.csv("200614COVID19MEXICO.csv",sep=",",header=T)
object.size(bd1)
head(bd1)
#paso 1: tener un directorio para archivos temporales de ff
system("mkdir ffdf")
#paso 2: definir la carpeta temporal
options(fftempdir="C:\\Users\\ALVARO\\Desktop\\db_bolivia\\bigdata\\ffdf")
#paso 3: Cargar la base de datos
bd2<-read.csv.ffdf(file="200614COVID19MEXICO.csv",sep=",",header=T,
                   next.rows=100000,colClasses=NA,VERBOSE=F)
bd3<-read.csv.ffdf(file="200614COVID19MEXICO.csv",sep=",",header=T,
                   first.rows=-1,colClasses=NA,VERBOSE=T)
bd4<-read.csv.ffdf(file="200614COVID19MEXICO.csv",sep=",",header=T,
                   next.rows=1000,colClasses=NA,VERBOSE=T)

object.size(bd1)/1000000 # CSV DE R
object.size(bd2)/1000000 # CSV.FFDF 100000
object.size(bd3)/1000000 # CSV.FFDF TODO
object.size(bd4)/1000000 # CSV.FFDF 1000

#USO DE LAS FFDF
table(bd2$SEXO)
barplot(table(bd2$SEXO))
library(tictoc)
tic("R")
table(bd1$SEXO)
toc()

tic("ffdf")
table(bd2$SEXO)
toc()

tic("ffdf table")
table.ff(bd2$SEXO)
toc()

#R: 1 G -> 
#FFDF: 200 M -> 
class(bd1)
class(bd2)
bd5<-as.data.frame.ffdf(bd2)
library(Hmisc)
describe(bd1)
describe(bd5)
object.size(bd5)
object.size(bd1)
object.size(bd2)
```


### Modelogs GLM con la las librerias ff y ffbase

### Expandiendo la memoria con la libreria bigmemory

## Parallel R

## Ejercicios Propuestos